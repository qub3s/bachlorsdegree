{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/georg.eckardt/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from skimage import filters, color, morphology\n",
    "from skimage.segmentation import flood, flood_fill\n",
    "import skimage\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Depth Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"depth-estimation\", model=\"LiheYoung/depth-anything-small-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /user/georg.eckardt/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /user/georg.eckardt/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"vit_b\"\n",
    "sam_checkpoint = \"model/\"+model_type+\".pth\"\n",
    "\n",
    "torch.cuda.set_device(7)\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(\"cuda\")\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def calc_center( mask ):\n",
    "    coords = np.where(mask==True)\n",
    "    x = coords[0].sum() / coords[0].shape\n",
    "    y = coords[1].sum() / coords[1].shape\n",
    "\n",
    "    return int(y), int(x)\n",
    "\n",
    "def calc_iou(im_1, im_2):\n",
    "    intersection = np.logical_and(im_1, im_2)\n",
    "    union = np.logical_or(im_1,im_2)\n",
    "\n",
    "    return np.sum(intersection)/np.sum(union)\n",
    "\n",
    "def calc_best_subset(masks, num_masks, min_masks):\n",
    "    # PERFORMANCE BOOST: Sort out masks with very high overlap and try the out later\n",
    "    # Sort out masks with clear cut boundaries\n",
    "    min_value = float(\"inf\")\n",
    "    min_arr = []\n",
    "\n",
    "    # add empty masks\n",
    "    for i in range(num_masks-min_masks):\n",
    "        masks.append(np.zeros((128,128)))\n",
    "    \n",
    "    min_value, min_arr = iteration_layer(min_value, min_arr, [], num_masks, masks)\n",
    "\n",
    "    return min_arr\n",
    "\n",
    "def mkdir(s):\n",
    "    try:\n",
    "        os.mkdir(s)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def three_dim(x):\n",
    "    return np.stack( ( x.copy()*234, x.copy()*345, x.copy()*567 ), 2).astype(np.uint8)  \n",
    "\n",
    "def three_dim_bw(x):\n",
    "    return np.stack( ( x.copy()*255, x.copy()*255, x.copy()*255 ), 2).astype(np.uint8)  \n",
    "\n",
    "def create_video(s):\n",
    "    return cv2.VideoWriter(s,cv2.VideoWriter_fourcc(*'mp4v'), 12, (128,128))\n",
    "\n",
    "def iteration_layer(min_value, min_arr, current_arr, level, masks, starting_index=0):\n",
    "    if level == 0:\n",
    "        uni_map = np.zeros((128,128))\n",
    "        for x in range(len(current_arr)):\n",
    "            uni_map += masks[current_arr[x]] \n",
    "        full_score = np.absolute(uni_map-1).sum()   \n",
    "        # check for new best\n",
    "        if full_score < min_value:\n",
    "            min_arr = current_arr.copy()\n",
    "            del current_arr[-1]\n",
    "            return full_score, min_arr\n",
    "        else:\n",
    "            del current_arr[-1]\n",
    "            return min_value, min_arr\n",
    "    \n",
    "    for i in range(starting_index,len(masks)):\n",
    "        current_arr.append(i)\n",
    "        min_value, min_arr = iteration_layer(min_value, min_arr, current_arr, level-1, masks, i+1)\n",
    "        \n",
    "    try:\n",
    "        del current_arr[-1]\n",
    "    except:\n",
    "        pass\n",
    "    return min_value, min_arr\n",
    "\n",
    "def create_sobel(frame):\n",
    "    return np.array(filters.sobel(frame))\n",
    "\n",
    "def calc_centers_colormean(regions,frame):\n",
    "    center = []\n",
    "    color_mean = []\n",
    "        \n",
    "    for k in range(np.unique(regions).shape[0]):\n",
    "        area = regions == k\n",
    "        size = area.sum()\n",
    "        center.append( calc_center(area) )\n",
    "        color_mean.append( (area  * ((frame[..., 0] + frame[..., 1] + frame[..., 2] )/3).astype(np.uint8)).sum()/ size )\n",
    "    \n",
    "    return center, color_mean\n",
    "\n",
    "def display_pointers(center, image):\n",
    "    for x in range(len(center)):\n",
    "            image = cv2.circle( image, (int(center[x][0]), int(center[x][1])), 3, (255, 255, 255) )\n",
    "    return image\n",
    "\n",
    "def display_bb(bbs, image):\n",
    "    for bb in bbs:\n",
    "            p1 = (bb[0][1], bb[0][0])\n",
    "            p2 = (bb[1][1], bb[1][0])\n",
    "            image = cv2.rectangle(image, p1,p2, (0,0,255), 1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def bw_frame(frame):\n",
    "    return (frame[...,0] + frame[...,1] + frame[...,2])/3\n",
    "\n",
    "def normalise(x):\n",
    "    x = np.array(x)\n",
    "    std = x.std()\n",
    "    if std == 0:\n",
    "        return (x-x.mean())\n",
    "    else:\n",
    "        return (x-x.mean())/std\n",
    "\n",
    "def point_dist(p1,p2):\n",
    "    return math.sqrt( (p1[0]-p2[0])**2 + (p1[1]-p2[1])**2  )\n",
    "\n",
    "# Average distance between points is 1\n",
    "def calc_normalize(center):\n",
    "    centerx = np.array([ x  for x,y in center])\n",
    "    centery = np.array([ y  for x,y in center])\n",
    "    norm_center = np.stack((centerx.copy(), centery.copy()), axis=-1)\n",
    "\n",
    "    distance = []\n",
    "    for i,p1 in enumerate(center):\n",
    "        for j,p2 in enumerate(center):\n",
    "            if i != j:\n",
    "                distance.append( point_dist(p1,p2) )\n",
    "    \n",
    "    distance = np.array(distance)\n",
    "\n",
    "    return norm_center/distance.mean()\n",
    "\n",
    "def calc_centerdepth(center, dist):\n",
    "    centerdist = []\n",
    "    for x in center:\n",
    "        centerdist.append(dist[x[0]][x[1]])\n",
    "    return centerdist\n",
    "\n",
    "def calc_div_matrix(color_mean):\n",
    "    size = len(color_mean)\n",
    "    color_mean = np.array(color_mean)\n",
    "    matrix = np.zeros((size,size))\n",
    "                      \n",
    "    for x in range(size):\n",
    "        matrix[x] = color_mean - color_mean[x]\n",
    "    \n",
    "    return np.absolute( matrix )\n",
    "\n",
    "def calc_dist_matrix(points):\n",
    "    size = points.shape[0]\n",
    "    centerx = points[:,0]\n",
    "    centery = points[:,1]\n",
    "\n",
    "    matrix = np.zeros((size,size))\n",
    "                      \n",
    "    for x in range(size):\n",
    "        matrix[x] = np.sqrt((centerx - centerx[x])**2 + (centery - centery[x])**2)\n",
    "    \n",
    "    return np.absolute( matrix )\n",
    "\n",
    "def get_bb(images):\n",
    "    bb = []\n",
    "    for im in images:\n",
    "        x, y = np.where(im != 0)\n",
    "        bb.append( ( (x.min(), y.min()), (x.max(), y.max() ) ) )\n",
    "        \n",
    "    return bb\n",
    "\n",
    "def calc_depth_mean(depth, mask_arr):\n",
    "    mean_depths = []\n",
    "    for mask in mask_arr:\n",
    "        area = depth * mask\n",
    "        mean = area.sum() / (area != 0).sum()\n",
    "        max_diff = area.max()-area.min()\n",
    "        mean_depths.append( (mean, max_diff) )\n",
    "\n",
    "    return mean_depths\n",
    "\n",
    "# unify masks\n",
    "def unify_masks_by_iou(mask_all, iou_thresh):\n",
    "    len_mask_all = len(mask_all)\n",
    "    iou_err = np.zeros((len_mask_all,len_mask_all))\n",
    "\n",
    "    for n in range(len_mask_all):\n",
    "        for m in range(n):\n",
    "            if n != m:\n",
    "                iou = calc_iou(mask_all[n], mask_all[m])\n",
    "                iou_err[n][m] = iou\n",
    "                iou_err[m][n] = iou\n",
    "\n",
    "    remove_list = []\n",
    "    for n in range(len_mask_all):\n",
    "        for m in range(len_mask_all):\n",
    "            if n != m and n not in remove_list and iou_err[n][m] > iou_thresh:\n",
    "                mask_all[n] = np.logical_or(mask_all[n],mask_all[m])\n",
    "                remove_list.append(m)\n",
    "    \n",
    "    # remove remove_list\n",
    "    new_masks = []\n",
    "    for x in range(len_mask_all):\n",
    "        if x not in remove_list:\n",
    "            new_masks.append(mask_all[x])\n",
    "    \n",
    "    return new_masks\n",
    "\n",
    "def background_removal(masks, mask_depth_vis, threshhold_depth):\n",
    "    mean = mask_depth_vis[:,1].mean()\n",
    "    foreground_masks = []\n",
    "    for i,x in enumerate(mask_depth_vis):\n",
    "        if scipy.stats.norm(mean, 0.2).pdf(x[0]) > threshhold_depth:\n",
    "            foreground_masks.append(masks[i])\n",
    "            \n",
    "    return foreground_masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.5462109963268498\n",
      "0.5195673681035236\n",
      "\n",
      "1\n",
      "0.2902630277230174\n",
      "0.2691966709820804\n",
      "\n",
      "2\n",
      "0.6322431615690484\n",
      "0.6322431615690484\n",
      "\n",
      "3\n",
      "0.31584664168490223\n",
      "0.39336137626861545\n",
      "\n",
      "4\n",
      "0.4599681367768105\n",
      "0.41517969073745437\n",
      "\n",
      "new params:\n",
      "iou_error:            0.8998200089999999\n",
      "lam_dis:              0.992518734375\n",
      "lam_col:              0.9428927976562501\n",
      "number_of_masks:      28.357678125\n",
      "bb_max_size:          5447.679999999999\n",
      "threshhold_depth:     0.09975\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, -1, 256, 256] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 217\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# 0.42953019158842976\u001b[39;00m\n\u001b[1;32m    216\u001b[0m parameter_fitting_all(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m \u001b[43mcheck_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [32], line 213\u001b[0m, in \u001b[0;36mcheck_parameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m rand_images \u001b[38;5;241m=\u001b[39m [ x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m) ]\n\u001b[1;32m    212\u001b[0m rand_frames \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;241m0\u001b[39m ]\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrand_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrand_frames\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn [32], line 114\u001b[0m, in \u001b[0;36mget_results\u001b[0;34m(rand_images, rand_frames)\u001b[0m\n\u001b[1;32m    111\u001b[0m bb_num \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(bb_num)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m transformed_boxes \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mapply_boxes_torch(bb_num, frame\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 114\u001b[0m masks, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoint_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoint_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformed_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultimask_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# merge masks with high iou\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/segment_anything/predictor.py:229\u001b[0m, in \u001b[0;36mSamPredictor.predict_torch\u001b[0;34m(self, point_coords, point_labels, boxes, mask_input, multimask_output, return_logits)\u001b[0m\n\u001b[1;32m    222\u001b[0m sparse_embeddings, dense_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mprompt_encoder(\n\u001b[1;32m    223\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints,\n\u001b[1;32m    224\u001b[0m     boxes\u001b[38;5;241m=\u001b[39mboxes,\n\u001b[1;32m    225\u001b[0m     masks\u001b[38;5;241m=\u001b[39mmask_input,\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Predict masks\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m low_res_masks, iou_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_pe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dense_pe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_prompt_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdense_prompt_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultimask_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultimask_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Upscale the masks to the original image resolution\u001b[39;00m\n\u001b[1;32m    238\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpostprocess_masks(low_res_masks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_size)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/segment_anything/modeling/mask_decoder.py:94\u001b[0m, in \u001b[0;36mMaskDecoder.forward\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, multimask_output)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     73\u001b[0m     image_embeddings: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     multimask_output: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m     78\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    Predict masks given image and prompt embeddings.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m      torch.Tensor: batched predictions of mask quality\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     masks, iou_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_masks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_pe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_pe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse_prompt_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_prompt_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdense_prompt_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_prompt_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Select the correct mask or masks for output\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multimask_output:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/segment_anything/modeling/mask_decoder.py:144\u001b[0m, in \u001b[0;36mMaskDecoder.predict_masks\u001b[0;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings)\u001b[0m\n\u001b[1;32m    142\u001b[0m hyper_in \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(hyper_in_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    143\u001b[0m b, c, h, w \u001b[38;5;241m=\u001b[39m upscaled_embedding\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 144\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mhyper_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupscaled_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Generate mask quality predictions\u001b[39;00m\n\u001b[1;32m    147\u001b[0m iou_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miou_prediction_head(iou_token_out)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [0, -1, 256, 256] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "iou_error = 0.9\n",
    "lam_dis = 1\n",
    "lam_col = 1\n",
    "num_masks_removal = 3\n",
    "number_of_masks = 30\n",
    "bb_max_size = (128*128)/3\n",
    "threshhold_depth = 0.1\n",
    "\n",
    "def get_results(rand_images, rand_frames):\n",
    "\n",
    "    error = 0\n",
    "\n",
    "    for i in rand_images:\n",
    "        mkdir(\"images/\"+str(i)+\"/\")\n",
    "        data = np.load('data/MOVIE/videos/'+str(i)+'.npy')\n",
    "        annotation = np.load('data/MOVIE/segmentations/'+str(i)+'.npy')\n",
    "\n",
    "        for xsx in rand_frames:\n",
    "            frame = data[xsx]\n",
    "            an = annotation[xsx]\n",
    "            bw_image = bw_frame(frame.copy())\n",
    "            norm_bw = normalise(bw_image.copy())\n",
    "\n",
    "            # predict the depth values\n",
    "            depth_vals = np.array(pipe(Image.fromarray(bw_image.copy()))[\"depth\"])\n",
    "\n",
    "            sobel = create_sobel(norm_bw.copy())\n",
    "            sobel = np.digitize(sobel, bins=[sobel.mean()]).astype(np.uint8)\n",
    "\n",
    "\n",
    "            sobel = np.digitize(sobel, bins=[sobel.mean()]).astype(np.uint8)\n",
    "            regions = skimage.morphology.label(sobel,1)\n",
    "\n",
    "            center, color_mean = calc_centers_colormean(regions.copy(), frame.copy())\n",
    "\n",
    "            save_regions = 0\n",
    "\n",
    "            while len(center) > number_of_masks:\n",
    "                centerdepth = normalise(calc_centerdepth(center, depth_vals))\n",
    "                norm_center = normalise(calc_normalize(center.copy()))\n",
    "\n",
    "                dis_mat = calc_div_matrix(centerdepth)\n",
    "                col_mat = calc_div_matrix(color_mean)\n",
    "                cen_mat = calc_dist_matrix(norm_center)\n",
    "\n",
    "                \n",
    "                lam_cen = 1/cen_mat.std()**2\n",
    "\n",
    "                dis = lam_dis * math.e**(-lam_dis * dis_mat)\n",
    "                col = lam_col * math.e**(-lam_col * col_mat)\n",
    "                cen = lam_cen * math.e**(-lam_cen * cen_mat)\n",
    "\n",
    "                uni = ( dis + col + cen )/3\n",
    "                uni *= np.identity(uni.shape[0]) == False           # remove center values \n",
    "                \n",
    "\n",
    "                for j in range(num_masks_removal):\n",
    "                    if len(center)-j > number_of_masks:\n",
    "                        maxi = np.unravel_index(uni.argmax(), uni.shape)\n",
    "                        uni[maxi[0]][maxi[1]] = 0\n",
    "                        regions += (regions == maxi[0])*(maxi[1]-maxi[0])\n",
    "                        regions = np.digitize(regions, bins=np.unique(regions))-1\n",
    "                        save_regions = regions.copy()\n",
    "\n",
    "                center, color_mean = calc_centers_colormean(regions, frame.copy())\n",
    "            \n",
    "            save_center = center.copy()\n",
    "            \n",
    "            # Predict the Masks\n",
    "            mask_all = []\n",
    "            score_all = []\n",
    "            predictor.set_image(frame.copy())\n",
    "            for point in center:\n",
    "                point = np.expand_dims(np.array(point), axis=0)\n",
    "                mask, score, _  = predictor.predict( point_coords=point, point_labels=[1])\n",
    "                mask_all.append(mask[0])\n",
    "                score_all.append(score[0])\n",
    "\n",
    "            all_centers = display_pointers(center.copy(), frame.copy())\n",
    "            \n",
    "            # check for the largest cluster | remove all smaller cluster\n",
    "            for m, mask in enumerate(mask_all):\n",
    "                mask_regions = (skimage.morphology.label(mask,background=-1,connectivity=1)+1) * mask\n",
    "                largest_mask = 0\n",
    "                size = 0\n",
    "\n",
    "                for ind in range(1, mask_regions.max()+2):\n",
    "                    area = (mask_regions == ind).sum()\n",
    "                    if area > size:\n",
    "                        largest_mask = ind\n",
    "                        size = area\n",
    "                \n",
    "                mask_all[m] = (mask_regions == largest_mask)\n",
    "            \n",
    "            # get upper/lower and left/right bounds\n",
    "            bb = get_bb(mask_all)\n",
    "\n",
    "            for x, mask in enumerate(mask_all):\n",
    "                save = display_bb([bb[x]],three_dim(mask))\n",
    "            \n",
    "            save = display_bb(bb,frame.copy())\n",
    "\n",
    "            new_bb = []\n",
    "            old_bb = []\n",
    "            for c, ((x1, y1), (x2, y2)) in enumerate(bb):\n",
    "                if (x2-x1)*(y2-y1) < bb_max_size:\n",
    "                    new_bb.append( [y1, x1, y2, x2] )\n",
    "                    old_bb.append( bb[c] )\n",
    "            \n",
    "            bb_num = np.array( new_bb )\n",
    "            bb_num = torch.from_numpy(bb_num).to(\"cuda\")\n",
    "\n",
    "            # WHAT TO DO IF THERE ARE NO BOXES\n",
    "            transformed_boxes = predictor.transform.apply_boxes_torch(bb_num, frame.shape[:2])\n",
    "            masks, _, _ = predictor.predict_torch(\n",
    "                point_coords=None,\n",
    "                point_labels=None,\n",
    "                boxes=transformed_boxes,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "            \n",
    "            masks = masks.cpu().numpy().squeeze()\n",
    "\n",
    "            # merge masks with high iou\n",
    "            masks = unify_masks_by_iou(list(masks), iou_error)\n",
    "            # sort masks by size (smallest first)\n",
    "            masks.sort( key = lambda masks: masks.sum() )\n",
    "            \n",
    "            # Foreground Background Distingtion (take mean of mean depths of all masks and then model normal distirbution with std as learnable parameter )\n",
    "            np_mask_depth = np.array(calc_depth_mean(normalise(depth_vals.copy()), masks))\n",
    "            np_mask_depth +=  np_mask_depth.min()*-1\n",
    "            mask_depth_vis = np_mask_depth / np_mask_depth.max()\n",
    "\n",
    "            masks = background_removal(masks, mask_depth_vis, threshhold_depth)\n",
    "\n",
    "            # add masks together\n",
    "            final = np.zeros((128,128))\n",
    "            for x, mask in enumerate(masks):\n",
    "                non_overlap = (final == 0) * mask\n",
    "                deep = mask_depth_vis[x][0]\n",
    "                final = final + non_overlap * (x+1)\n",
    "            \n",
    "            cv2.imwrite(\"images/\"+str(i)+\"/final.jpg\", three_dim(final))\n",
    "            cv2.imwrite(\"images/\"+str(i)+\"/ann.jpg\", three_dim(an.squeeze()) )\n",
    "\n",
    "            error = error + calc_iou(final,an.squeeze())\n",
    "\n",
    "    return error / (len(rand_images) * len(rand_frames))\n",
    "\n",
    "\n",
    " # iou_error   lam_dis   lam_col   num_masks_removal   number_of_masks   bb_max_size   threshhold_depth\n",
    "def change_params( direction, change ):\n",
    "    global iou_error   \n",
    "    global lam_dis   \n",
    "    global lam_col   \n",
    "    global number_of_masks   \n",
    "    global bb_max_size   \n",
    "    global threshhold_depth\n",
    "    \n",
    "    iou_error = iou_error + (change[0] * iou_error * direction[0] )\n",
    "    lam_dis = lam_dis + (change[1] * lam_dis * direction[1] )\n",
    "    lam_col = lam_col + (change[2] * lam_col * direction[2] )\n",
    "    number_of_masks = number_of_masks + (change[3] * number_of_masks * direction[3] )\n",
    "    bb_max_size = bb_max_size + (change[4] * bb_max_size * direction[4] )\n",
    "    threshhold_depth = threshhold_depth + (change[5] * threshhold_depth * direction[5] )\n",
    "    return\n",
    "\n",
    "def print_params():\n",
    "    global iou_error   \n",
    "    global lam_dis   \n",
    "    global lam_col   \n",
    "    global number_of_masks   \n",
    "    global bb_max_size   \n",
    "    global threshhold_depth\n",
    "    print(\"new params:\")\n",
    "    print(\"iou_error:           \",str(iou_error))\n",
    "    print(\"lam_dis:             \",str(lam_dis))\n",
    "    print(\"lam_col:             \",str(lam_col))\n",
    "    print(\"number_of_masks:     \",str(number_of_masks))\n",
    "    print(\"bb_max_size:         \",str(bb_max_size))\n",
    "    print(\"threshhold_depth:    \",str(threshhold_depth))\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "def parameter_fitting_all(epochs, iterations, im_per_iter):\n",
    "    change = [0.01, 0.05, 0.05, 0.05, 0.05, 0.05 ]\n",
    "\n",
    "    for x in range(epochs):\n",
    "        print(x)\n",
    "        direction_of_change = np.array([random.randint(-1,1) for x in range(6)])\n",
    "\n",
    "        rand_images = [ random.randint(0,50) for x in range(iterations) ]\n",
    "        rand_frames = [ random.randint(0,23) for x in range(im_per_iter) ]\n",
    "\n",
    "        p1 = get_results(rand_images,rand_frames)\n",
    "\n",
    "        change_params(direction_of_change, change)\n",
    "        \n",
    "        p2 = get_results(rand_images,rand_frames)\n",
    "        \n",
    "        if p2 < p1:\n",
    "            change_params(direction_of_change*-1, change)\n",
    "        \n",
    "        print(p1)\n",
    "        print(p2)\n",
    "        print()\n",
    "    \n",
    "    print_params()\n",
    "\n",
    "def check_parameters():\n",
    "    rand_images = [ x for x in range(50) ]\n",
    "    rand_frames = [ 0 ]\n",
    "    print(get_results(rand_images,rand_frames))\n",
    "\n",
    "# 0.42953019158842976\n",
    "parameter_fitting_all(5, 3, 3)\n",
    "check_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: 0\n",
      "14\n",
      "14\n",
      "0.20943979750752567\n",
      "0.25178137610722273\n",
      "0.16541378112030702\n",
      "0.6360696773201121\n",
      "0.7824957290395488\n",
      "0.6864540706631811\n",
      "1.345673938354527\n",
      "1.891257060865595\n",
      "8\n",
      "0 0.019022858802571856\n",
      "1 0.07262203028921688\n",
      "2 0.3616317782235253\n",
      "3 0.37934601846829685\n",
      "4 0.3399549333515471\n",
      "5 0.2132874808373096\n",
      "6 0.21718919740786283\n",
      "7 0.4838722842549318\n"
     ]
    }
   ],
   "source": [
    "iou_error = 0.9\n",
    "lam_dis = 1\n",
    "lam_col = 1\n",
    "num_masks_removal = 3\n",
    "number_of_masks = 30\n",
    "bb_max_size = (128*128)/3\n",
    "threshhold_depth = 0.1\n",
    "\n",
    "for i in range(1):\n",
    "    print(\"Video: \"+str(i))\n",
    "    mkdir(\"images/\"+str(i)+\"/\")\n",
    "\n",
    "    data = np.load('data/MOVIE/videos/'+str(i)+'.npy')\n",
    "    annotation = np.load('data/MOVIE/segmentations/'+str(i)+'.npy')\n",
    "\n",
    "    \n",
    "    for frame in data:\n",
    "        bw_image = bw_frame(frame.copy())\n",
    "        norm_bw = normalise(bw_image.copy())\n",
    "\n",
    "        # predict the depth values\n",
    "        depth_vals = np.array(pipe(Image.fromarray(bw_image.copy()))[\"depth\"])\n",
    "\n",
    "        sobel = create_sobel(norm_bw.copy())\n",
    "        sobel = np.digitize(sobel, bins=[sobel.mean()]).astype(np.uint8)\n",
    "\n",
    "\n",
    "        sobel = np.digitize(sobel, bins=[sobel.mean()]).astype(np.uint8)\n",
    "        regions = skimage.morphology.label(sobel,1)\n",
    "\n",
    "        center, color_mean = calc_centers_colormean(regions.copy(), frame.copy())\n",
    "\n",
    "        save_regions = 0\n",
    "\n",
    "        while len(center) > number_of_masks:\n",
    "            centerdepth = normalise(calc_centerdepth(center, depth_vals))\n",
    "            norm_center = normalise(calc_normalize(center.copy()))\n",
    "\n",
    "            dis_mat = calc_div_matrix(centerdepth)\n",
    "            col_mat = calc_div_matrix(color_mean)\n",
    "            cen_mat = calc_dist_matrix(norm_center)\n",
    "\n",
    "            \n",
    "            lam_cen = 1/cen_mat.std()**2\n",
    "\n",
    "            dis = lam_dis * math.e**(-lam_dis * dis_mat)\n",
    "            col = lam_col * math.e**(-lam_col * col_mat)\n",
    "            cen = lam_cen * math.e**(-lam_cen * cen_mat)\n",
    "\n",
    "            uni = ( dis + col + cen )/3\n",
    "            uni *= np.identity(uni.shape[0]) == False           # remove center values \n",
    "            \n",
    "\n",
    "            for j in range(num_masks_removal):\n",
    "                if len(center)-j > number_of_masks:\n",
    "                    maxi = np.unravel_index(uni.argmax(), uni.shape)\n",
    "                    uni[maxi[0]][maxi[1]] = 0\n",
    "                    regions += (regions == maxi[0])*(maxi[1]-maxi[0])\n",
    "                    regions = np.digitize(regions, bins=np.unique(regions))-1\n",
    "                    save_regions = regions.copy()\n",
    "\n",
    "            center, color_mean = calc_centers_colormean(regions, frame.copy())\n",
    "        \n",
    "        save_center = center.copy()\n",
    "        \n",
    "        # Predict the Masks\n",
    "        mask_all = []\n",
    "        score_all = []\n",
    "        predictor.set_image(frame.copy())\n",
    "        for point in center:\n",
    "            point = np.expand_dims(np.array(point), axis=0)\n",
    "            mask, score, _  = predictor.predict( point_coords=point, point_labels=[1])\n",
    "            mask_all.append(mask[0])\n",
    "            score_all.append(score[0])\n",
    "\n",
    "        all_centers = display_pointers(center.copy(), frame.copy())\n",
    "        \n",
    "        # check for the largest cluster | remove all smaller cluster\n",
    "        for m, mask in enumerate(mask_all):\n",
    "            mask_regions = (skimage.morphology.label(mask,background=-1,connectivity=1)+1) * mask\n",
    "            largest_mask = 0\n",
    "            size = 0\n",
    "\n",
    "            for ind in range(1, mask_regions.max()+2):\n",
    "                area = (mask_regions == ind).sum()\n",
    "                if area > size:\n",
    "                    largest_mask = ind\n",
    "                    size = area\n",
    "            \n",
    "            mask_all[m] = (mask_regions == largest_mask)\n",
    "        \n",
    "        # get upper/lower and left/right bounds\n",
    "        bb = get_bb(mask_all)\n",
    "\n",
    "        for x, mask in enumerate(mask_all):\n",
    "            save = display_bb([bb[x]],three_dim(mask))\n",
    "        \n",
    "        save = display_bb(bb,frame.copy())\n",
    "\n",
    "        new_bb = []\n",
    "        old_bb = []\n",
    "        for c, ((x1, y1), (x2, y2)) in enumerate(bb):\n",
    "            if (x2-x1)*(y2-y1) < bb_max_size:\n",
    "                new_bb.append( [y1, x1, y2, x2] )\n",
    "                old_bb.append( bb[c] )\n",
    "        \n",
    "        bb_num = np.array( new_bb )\n",
    "        bb_num = torch.from_numpy(bb_num).to(\"cuda\")\n",
    "\n",
    "        transformed_boxes = predictor.transform.apply_boxes_torch(bb_num, frame.shape[:2])\n",
    "        masks, _, _ = predictor.predict_torch(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            boxes=transformed_boxes,\n",
    "            multimask_output=False,\n",
    "        )\n",
    "\n",
    "        masks = masks.cpu().numpy().squeeze()\n",
    "\n",
    "        # merge masks with high iou\n",
    "        masks = unify_masks_by_iou(list(masks), iou_error)\n",
    "        # sort masks by size (smallest first)\n",
    "        masks.sort( key = lambda masks: masks.sum() )\n",
    "\n",
    "        print(len(masks))\n",
    "\n",
    "        # Foreground Background Distingtion (take mean of mean depths of all masks and then model normal distirbution with std as learnable parameter )\n",
    "        mask_depth = np.array(calc_depth_mean(normalise(depth_vals.copy()), masks))\n",
    "        np_mask_depth +=  np_mask_depth.min()*-1\n",
    "        mask_depth_vis = np_mask_depth / np_mask_depth.max()\n",
    "\n",
    "        masks = background_removal(masks, mask_depth_vis, threshhold_depth)\n",
    "\n",
    "        # add masks together\n",
    "        final = np.zeros((128,128))\n",
    "        for x, mask in enumerate(masks):\n",
    "            cv2.imwrite(\"images/\"+str(i)+\"/\"+str(x)+\"simple_mask.jpg\", three_dim_bw(mask))\n",
    "            non_overlap = (final == 0) * mask\n",
    "            deep = mask_depth_vis[x][0]\n",
    "            cv2.imwrite(\"images/\"+str(i)+\"/\"+str(x)+\"mask_depth.jpg\", three_dim_bw(deep * non_overlap))\n",
    "            \n",
    "            final = final + non_overlap * (x+1)\n",
    "            #print(final.max())\n",
    "\n",
    "\n",
    "\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/depth.jpg\", three_dim_bw(depth_vals/depth_vals.max()))\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/regions.jpg\", three_dim(save_regions))\n",
    "        save = display_pointers(save_center,three_dim(annotation[i].squeeze()))\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/centers.jpg\", save)\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/final.jpg\", three_dim(final))\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/clean.jpg\", frame.copy())\n",
    "        save = display_bb(old_bb,three_dim(annotation[i].squeeze()))\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/ann.jpg\", save )\n",
    "        \n",
    "        break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n \\n\\n # save images\\n for c in range(len(mask_all)):\\n     save = np.stack( ( mask_all[c].copy()*255, mask_all[c].copy()*128, mask_all[c].copy()*56 ), 2).astype(np.uint8)    \\n     save = cv2.circle( save, (int(center[c][0]), int(center[c][1])), 3, (255, 255, 255) )\\n     cv2.imwrite(\"images/\"+str(i)+\"/\"+str(c)+\".jpg\", save)\\n \\n # save annotation\\n for x in range(len(mask_all)):\\n     annotation = cv2.circle( annotation, (int(center[x][0]), int(center[x][1])), 3, (255, 255, 255) )\\n \\n # Calc best Subset | ALTERNATIVE (GET BOUNDING BOXES FOR ALL THE IMAGES AND THEN RUN SAM AGAIN)\\n min_arr = calc_best_subset(mask_all, number_of_mask_final_assamble, 2)\\n final = np.zeros((128,128))\\n for f, ids in enumerate(min_arr):\\n     final += mask_all[ids]*(f+1)\\n final = np.stack( ( final.copy()*234, final.copy()*345, final.copy()*567 ), 2).astype(np.uint8)  \\n\\n print(\"done\"+str(i))\\n cv2.imwrite(\"images/\"+str(i)+\"/all_centers.jpg\", all_centers)\\n \\n cv2.imwrite(\"images/\"+str(i)+\"/final.jpg\", final)\\n cv2.imwrite(\"images/\"+str(i)+\"/without.jpg\", frame)\\n '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "       '''\n",
    "\n",
    "        \n",
    "\n",
    "        # save images\n",
    "        for c in range(len(mask_all)):\n",
    "            save = np.stack( ( mask_all[c].copy()*255, mask_all[c].copy()*128, mask_all[c].copy()*56 ), 2).astype(np.uint8)    \n",
    "            save = cv2.circle( save, (int(center[c][0]), int(center[c][1])), 3, (255, 255, 255) )\n",
    "            cv2.imwrite(\"images/\"+str(i)+\"/\"+str(c)+\".jpg\", save)\n",
    "        \n",
    "        # save annotation\n",
    "        for x in range(len(mask_all)):\n",
    "            annotation = cv2.circle( annotation, (int(center[x][0]), int(center[x][1])), 3, (255, 255, 255) )\n",
    "        \n",
    "        # Calc best Subset | ALTERNATIVE (GET BOUNDING BOXES FOR ALL THE IMAGES AND THEN RUN SAM AGAIN)\n",
    "        min_arr = calc_best_subset(mask_all, number_of_mask_final_assamble, 2)\n",
    "        final = np.zeros((128,128))\n",
    "        for f, ids in enumerate(min_arr):\n",
    "            final += mask_all[ids]*(f+1)\n",
    "        final = np.stack( ( final.copy()*234, final.copy()*345, final.copy()*567 ), 2).astype(np.uint8)  \n",
    "\n",
    "        print(\"done\"+str(i))\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/all_centers.jpg\", all_centers)\n",
    "        \n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/final.jpg\", final)\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/without.jpg\", frame)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (3361205629.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "        save = three_dim(regions.copy())  \n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/sobel_segmentation.jpg\", save)\n",
    "\n",
    "        center, color_mean = calc_centers_colormean(regions.copy(), frame.copy())\n",
    "\n",
    "\n",
    "        all_centers = display_pointers(center.copy(), frame.copy())\n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/all_centers.jpg\", all_centers)\n",
    "        \n",
    "        break\n",
    "        \n",
    "        # fuse and remove pointers\n",
    "        for n in range(len(center)):\n",
    "            for m in range(len(center)):\n",
    "                if n != m and math.sqrt(abs(center[n][0] - center[m][0])**2 + abs(center[n][1] - center[m][1])**2) < distance_for_fusing and abs(color_mean[n]-color_mean[m]) < color_grad_for_fusing:\n",
    "                    regions += (regions == m)*(n-m)\n",
    "\n",
    "        # restore counting from 0        \n",
    "        regions = np.digitize(regions, bins=np.unique(regions))-1\n",
    "        #print(regions.max())\n",
    "        save = np.stack( ( regions.copy()*255, regions.copy()*128, regions.copy()*56 ), 2).astype(np.uint8)    \n",
    "        cv2.imwrite(\"images/\"+str(i)+\"/regions.jpg\", save)\n",
    "        #plt.imshow(regions, cmap=\"prism\")\n",
    "\n",
    "\n",
    "        # recalculated center\n",
    "        center = []\n",
    "        color_mean = []\n",
    "        for k in range(np.unique(regions).shape[0]):\n",
    "            area = regions == k\n",
    "            center.append( calc_center(area) )\n",
    "        \n",
    "\n",
    "        # Predict Masks for all points (check if better with negative points)\n",
    "        mask_all = []\n",
    "        score_all = []\n",
    "        predictor.set_image(frame.copy())\n",
    "        for point in center:\n",
    "            point = np.expand_dims(np.array(point), axis=0)\n",
    "            mask, score, _  = predictor.predict( point_coords=point, point_labels=[1])\n",
    "            mask_all.append(mask[0])\n",
    "            score_all.append(score[0])\n",
    "\n",
    "\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
